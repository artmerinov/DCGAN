{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import set_random_seed\n",
    "from dataset import CelebaDataset, transform, augment, inverse_normalize\n",
    "from model import Discriminator, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(seed=0)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "LR = 2e-4\n",
    "BETAS = (0.5, 0.999)\n",
    "NOISE_DIM = 100\n",
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "celeba_dataset = CelebaDataset(folder_path='../../data/celeba_hq_256', transform=transform, augment=augment)\n",
    "dataloader = DataLoader(dataset=celeba_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "for x in dataloader:\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(noise_dim=NOISE_DIM, input_chanels=3).to(device)\n",
    "D = Discriminator(input_channels=3).to(device)\n",
    "\n",
    "if not os.path.exists('weights'):\n",
    "    os.makedirs('weights')\n",
    "    \n",
    "if not os.path.exists('genetated_images'):\n",
    "    os.makedirs('genetated_images')\n",
    "\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=LR, betas=BETAS)\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=LR, betas=BETAS)\n",
    "\n",
    "fixed_noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n",
    "generated_imgs = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    G.train()\n",
    "    D.train()\n",
    "    \n",
    "    g_loss_running = 0\n",
    "    d_loss_running = 0\n",
    "\n",
    "    for batch_id, real_batch in enumerate(dataloader):\n",
    "        \n",
    "        # -----------------------------------------\n",
    "        # 1. Update (improve) Discriminator network\n",
    "        # maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        # -----------------------------------------\n",
    "\n",
    "        real_batch = real_batch.to(device)\n",
    "        noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n",
    "        fake_batch = G(noise)\n",
    "\n",
    "        d_prob_real = D(real_batch).view(-1)\n",
    "        d_prob_fake = D(fake_batch).view(-1)\n",
    "        d_loss_real = criterion(d_prob_real, torch.ones_like(d_prob_real))\n",
    "        d_loss_fake = criterion(d_prob_fake, torch.zeros_like(d_prob_fake))\n",
    "        d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "        d_loss_running += d_loss.item()\n",
    "\n",
    "        D.zero_grad()\n",
    "        d_loss.backward(retain_graph=True) # we will reuse fake_batch in generator below\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 2. Update (improve) Generator network\n",
    "        # minimize log(1 - D(G(z))) <-> maximize log(D(G(z)))\n",
    "        # ---------------------------------------------------\n",
    "        \n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        d_prob = D(fake_batch).view(-1)\n",
    "        g_loss = criterion(d_prob, torch.ones_like(d_prob_real))\n",
    "        g_loss_running += g_loss.item()\n",
    "        \n",
    "        G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        if batch_id > 0 and batch_id % 50 == 0:\n",
    "            print(\n",
    "                f\"epoch={epoch}\",\n",
    "                f\"batch={batch_id:03d}/{len(dataloader)}\",\n",
    "                # d_loss is the quality of discriminator (the lower the better)\n",
    "                f\"d_loss={d_loss.item():.3f}\",\n",
    "                # g_loss is the quality of generator (the lower the better) \n",
    "                f\"g_loss={g_loss.item():.3f}\",\n",
    "                # D(x) is the average discriminator outputs for the real batch. \n",
    "                # This should start close to 1 and then converge to 0.5 as G gets better.\n",
    "                f\"D(x)={d_prob_real.mean().item():.3f}\",  \n",
    "                # D(G(z)) is the average discriminator outputs for the fake batch. \n",
    "                # This should start close to 0 and then converge to 0.5 as G gets better.\n",
    "                f\"D(G(z))={d_prob_fake.mean().item():.3f}\",\n",
    "            )\n",
    "    \n",
    "    print('************************************************************************')\n",
    "    print(\n",
    "        f\"epoch={epoch}\",\n",
    "        f\"d_loss={d_loss_running/len(dataloader):.3f}\",\n",
    "        f\"g_loss={g_loss_running/len(dataloader):.3f}\"\n",
    "    )\n",
    "    print('************************************************************************')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        fake_imgs = G(fixed_noise).detach().cpu()\n",
    "\n",
    "        fig, axs = plt.subplots(5,7, figsize=(7,5))\n",
    "        plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "        axs = axs.flatten()\n",
    "        for i in range(35):\n",
    "            axs[i].imshow(inverse_normalize(fake_imgs[i]).permute(1,2,0))\n",
    "            axs[i].axis('off')\n",
    "        plt.savefig(f'genetated_images/img_epoch{epoch:02d}.png', dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "torch.save(G.state_dict(), f\"weights/g_model_epoch_{epoch:02d}.pt\")\n",
    "torch.save(D.state_dict(), f\"weights/d_model_epoch_{epoch:02d}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
